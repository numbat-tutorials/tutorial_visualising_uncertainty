---
title: "WOMBAT 2025 Tutorial"
subtitle: "Visualising Uncertainty"
author: 
  - name: "Harriet Mason, Dianne Cook"
institute: "Department of Econometrics and Business Statistics"
format: 
  revealjs:
    theme: 
      - default 
      - custom.scss
    width: 1600
    height: 900
    margin: 0.1
    slide-number: c/t
    embed-resources: true
code-line-numbers: false
code-fold: true
message: false
highlight-style: pygments
title-slide-attributes:
  data-background-color: "#006dae"
  data-background-opacity: "0.5"
footer: "[https://numbat-tutorials.github.io/tutorial_visualising_uncertainty/](https://numbat-tutorials.github.io/tutorial_visualising_uncertainty/)"
---

```{r}
#| label: setup
#| include: false
library(ggplot2)
library(tidyr)
library(dplyr)
library(ggdibbler)
library(gt)
library(distributional)
library(cowplot)
library(gridExtra)
library(cartogram)
library(sf)
options(digits=3, 
        repr.plot.width=15,
        repr.plot.height=8)

# ![](images/){fig-align="center"}
```

# Session 2 <br> Diving deeper into uncertainty visualisation using examples in spatial data {.transition-slide style="align: center;"}

# Introduction to Spatial Visualisation {.transition-slide style="align: center;"}

## Why focus on spatial visualisations?

- Spatial case is a good example to work through because the aesthetics we have to express estimates are limited
- Maps take up most of the usual aesthetics by being a representation of space
  - position, size, shape, etc all have an implicit meaning in the mapping context
  - colour/fill is usually the only aesthetic we have left
  - can also get creative and do glyph maps (we will ignore this variation here)
- Once we have filled in a map, colour/fill is often the only aesthetic that has
        
## Citizen Scientist Data  

- There have been reports of a strange spatial pattern in the temperatures of Iowa
- We get some citizen scientists to measure data at their home and report back
- To maintain anonymity, we are only provided with the county of each scientist


```{r}
#| label: show-data
library(kableExtra)
temp_data <- toy_temp |>
  as_tibble() |>
  select(scientistID, county_name, recorded_temp) |>
  head(5)
kbl(temp_data)
```
`990` citizen scientists participated


## We could just plot the data...

- We often get spatial data in terms of longitude and latitude which we can plot directly

```{r}
#| echo: false
p_data <- ggplot(toy_temp) +
  geom_jitter(aes(x=county_longitude, y=county_latitude, colour=recorded_temp), 
              width=7000, height =7000, alpha=0.7) +
  theme_minimal() +
  labs(x = "Longitude",
       y = "Latitude",
       colour= "Temperature",
       title = "Citizen Scientist Recordings") +
  scale_colour_distiller(palette = "YlOrRd", direction= 1) +
  theme(aspect.ratio=0.7)
p_data
```

- This approach is easy but lacks the contextual information that gives our plots meaning.

## Spatial features objects

* SF objects are differentiated from a tibble because of additional metata in the Coordinate reference system (CRS). Specifically: 
  + Assumptions about the shape of the planet (geodetic datum)
  + Distortions we will/won't accept when drawing the map (map projection)
  
```{r}
#| label: make-map
#| echo: false
p_data_sf <- ggplot(toy_temp) +
  geom_sf(aes(geometry=county_geometry), fill="white") +
  geom_jitter(aes(x=county_longitude, y=county_latitude, colour=recorded_temp), 
              width=7000, height =7000, alpha=0.7) +
  theme_minimal() +
  labs(x = "Longitude",
       y = "Latitude",
       colour= "Temperature",
       title = "Citizen Scientist Recordings") +
  scale_colour_distiller(palette = "YlOrRd", direction= 1) +
  theme(aspect.ratio=0.7)
p_data_sf
```

## Can you see the spatial trend?

```{r}
p_data_sf
```



## Estimate the county mean

- Visualising an estimate, such as a mean, can make trends easier to see
  + Should use the sampling distribution, but often we do not bother...

```{r}
#| label: compute-summaries
#| include: false
# Calculate County Mean
mean_print <- toy_temp |> 
  group_by(county_name) |>
  summarise(temp_mean = mean(recorded_temp),
            temp_se = sd(recorded_temp)/sqrt(n()),
            n = n()) |>
  as_tibble() |>
  select(county_name, temp_mean, temp_se, n) |>
  head(5)

toy_temp_mean <- toy_temp |> 
  group_by(county_name, county_longitude, county_latitude) |>
  summarise(temp_mean = mean(recorded_temp),
            temp_se = sd(recorded_temp)/sqrt(n()),
            n = n()) |>
  ungroup()
```

```{r}
#| label: compute-mean
#| echo: true
#| eval: false
# Calculate County Mean
toy_temp |> 
  group_by(county_name) |>
  summarise(temp_mean = mean(recorded_temp),
            temp_se = sd(recorded_temp)/sqrt(n()),
            n = n()) 
```

```{r}
kbl(mean_print)
```

## Can you see the trend now?

```{r}
#| label: choropleth
p_choro <- ggplot(toy_temp_mean) +
  geom_sf(aes(geometry=county_geometry, fill=temp_mean), linewidth = 0, alpha=0.9) +
  theme_minimal() +
  scale_fill_distiller(palette = "YlOrRd", direction= 1) +
  xlab("Longitude") +
  ylab("Latitude") +
  labs(fill = "Temperature") +
  theme(aspect.ratio=0.7)
p_choro
```

## Common Map Visualisations

:::: {.columns}

::: {.column width="40%"}

* Usually spatial data is shown using a choropleth map
  + Choropleth maps shade an area according to an average or total
* We can also weight according to a different variable (such as sample size)
  + e.g. Cartograms, and Bubble plots

:::

::: {.column width="60%"}


::: {.panel-tabset}

## Choropleth Map

```{r}
p_choro
```

## Cartogram

```{r}
#| label: cartogram
# Make Cartogram using instructions from r graph gallery
toy_merc <- st_transform(toy_temp_mean, 3857)
toy_cartogram <- cartogram_cont(toy_merc, weight = "n", itermax = 5)
toy_cartogram <- st_transform(toy_cartogram, st_crs(toy_temp_mean))
# plot it
p_cartogram <- ggplot(toy_cartogram) +
  geom_sf(aes(fill = temp_mean), linewidth = 0, alpha = 0.9) +
  theme_minimal() +
  scale_fill_distiller(palette = "YlOrRd", direction= 1) +
  xlab("Longitude") +
  ylab("Latitude") +
  labs(fill = "Temperature") +
  theme(aspect.ratio=0.7)
p_cartogram
```


## Bubble Map

```{r}
#| label: bubble-plot
p_bubble <- ggplot(toy_temp_mean) +
  geom_sf(fill = "white", alpha = 0.9) +
  geom_point(aes(x=county_longitude, county_latitude,
                 colour=temp_mean, size=n), alpha=0.9) +
  theme_minimal() +
  scale_fill_distiller(palette = "YlOrRd", direction= 1) +
  xlab("Longitude") +
  ylab("Latitude") +
  labs(colour = "Temperature") +
  scale_colour_distiller(palette = "YlOrRd", direction= 1) +
  theme(aspect.ratio=0.7, legend.position="none")

p_bubble

```

:::

:::
::::

## But what if the error is worse? {.larger}

:::: {.columns}

::: {.column width=70%} 
- It turns out the citizen scientists are using some pretty old tools
- The standard error **could** be up to three times what we would estimate with our usual assumptions.
- We want to see both versions of the data so we can see the impact of this measurement error

```{r}
#| label: compute-var
#| include: false

# Calculate extra variance
toy_temp_comp <- toy_temp_mean |> 
  mutate(low_temp_se = temp_se,
         high_temp_se = 3*temp_se) |>
  select(-temp_se)
  
comp_print <- toy_temp_comp |>
  select(county_name, temp_mean, low_temp_se,
         high_temp_se, n) |>
  head(3)
```

```{r}
kbl(comp_print)
```
:::

::: {.column width=30%}
![](images/thermo.jpeg){#fig-thermo width=100%}
:::

::::

## Spot the difference
:::: {.columns}

::: {.column}

```{r}
#| fig-width: 10
#| fig-height: 7
#| out-width: 100%
p_choro + ggtitle("Low Standard Error")
```
:::

::: {.column}
```{r}
#| fig-width: 10
#| fig-height: 7
#| out-width: 100%
p_choro + ggtitle("High Standard Error")
```
:::

* One of these plots was made with the high standard error data, and the other was made with the low standard error data. Can you tell which is which?

::::

## Exercise 1

Make the high and low variance choropleth maps yourself, and see why they come out looking identical

# Approaches to Spatial Uncertainty {.transition-slide style="align: center;"}

## Solution 1: add an axis for uncertainty

```{r}
#| label: show-vizumap
# load the package
# remotes::install_github(repo = "lydialucchesi/Vizumap", build_vignettes = TRUE, force = TRUE)
library(Vizumap)

# load the upper Burdekin (UB) data and format it
data(UB) # this returns a data frame, UB_tss, and a shapefile, UB_shp
UB_dat <- read.uv(data = toy_temp_mean, estimate = "TSS", error = "TSS_error")

# build a bivariate color palette
UB_pal <- build_palette(name = "usr", colrange = list(colour = c("gold", "red4"), difC = c(4, 4)))

# build the bivariate map and key, and then attach the key to the map
UB_biv_map <- build_bmap(data = UB_dat, geoData = UB_shp, id = "scID", palette = UB_pal, terciles = TRUE)
UB_biv_key <- build_bkey(data = UB_dat, palette = UB_pal, terciles = TRUE)
attach_key(map = UB_biv_map, mapkey = UB_biv_key)
```


![](images/bivar.jpeg){fig-align="center"}

- Pro
  - Included uncertainty and increased transparency
- Cons
  - High uncertainty signal still very visible
  - 2D palette is harder to read
    - Colour is not a simple 3D space
    - Using saturation hurts accessibility

## Solution 2: blend the colours together

![](images/vsup.jpeg){fig-align="center"}

- Pros
  - Included uncertainty and increased transparency
  - Removed false signals
- Cons
  - Still have 2D Colour palette 
  - Standard error at which to blend colours is made up
    - Impossible to align with hypothesis testing
 
## Solution 3: simulate a sample

![](images/choro.jpeg){fig-align="center"}

- Pros
  - Included uncertainty 
  - High uncertainty interferes with reading of plot (?)
  - 1D colour palette 

## Popular R packages

* `ggdibbler`
  + Data: distribution from distributional
  + Maps: pixel map, other non-spatial maps
* `Vizumap`
  + Data: Depends on the plot. Can take a distribution as a q function (pixel), or an estimate and standard error as two variables (bivar/VSUP and glyph)
  + Maps: Biar/VSUP, pixel, glyph
* `biscale`
  + Data: Estimate and standard error as two variables
  + Maps: Biar/VSUP map


## Alternative software for incorperating uncertainty

- Existing tidy data structures are not great for uncertain data
- e.g. `Vizumap` 
  - Makes Bivariate maps and Pixel (sample) maps
  - Package is designed specifically for uncertainty
- Issues
  - `ggplot2` flexibility is lost
    - e.g. you can only use one of three specific palettes
  - *Very* computationally expensive
    - A simple map can take over a minute to run
  - Need to make every component separately then combine


# Making a Pixel Map with `ggdibbler` {.transition-slide style="align: center;"}

## `ggplot2` uses the grammar of graphics

![](images/gog1.jpg){fig-align="center"}


## It is designed to take in data

![](images/gog3.jpg){fig-align="center"}

## Not theoretical distributions

![](images/gog4.jpg){fig-align="center"}

## This is what `ggdibbler` is for

![](images/gog5.jpg){fig-align="center"}

## Basic `ggdibbler` Example

```{r}
#| label: ggdibbler1
#| echo: true
#| fig-align: center 

library(ggdibbler)
toy_temp_dist |> 
  ggplot() + 
  geom_sf_sample(aes(geometry = county_geometry,
                     fill=temp_dist))
```

## Can utilise ggplot2 flexibility

```{r}
#| label: ggdibbler2
#| echo: true
#| fig-align: center 
ggplot(toy_temp_dist) +
  geom_sf_sample(aes(geometry=county_geometry, fill=temp_dist),  linewidth=0, n=7) +
  geom_sf(aes(geometry = county_geometry), fill=NA, linewidth=0.5, colour="white") +
  theme_minimal() +
  scale_fill_distiller(palette = "YlOrRd", direction= 1) +
  xlab("Longitude") +
  ylab("Latitude") +
  labs(fill = "Temperature") +
  ggtitle("A super cool and customised plot")

```

## Remember, the plot is random

```{r}
#| label: ggdibbler3
#| echo: true
#| fig-align: center 
ggplot(toy_temp_dist) +
  geom_sf_sample(aes(geometry=county_geometry, fill=temp_dist),  linewidth=0, n=7) +
  geom_sf(aes(geometry = county_geometry), fill=NA, linewidth=0.5, colour="white") +
  theme_minimal() +
  scale_fill_distiller(palette = "YlOrRd", direction= 1) +
  xlab("Longitude") +
  ylab("Latitude") +
  labs(fill = "Temperature") +
  ggtitle("A super cool and customised plot")

```

## Exercise 2

Here is the code that was used to make the cartogram from earlier in the session. Can you make a ggdibbler verion of this plot?

```{r}
#| label: example2
#| echo: true
# Transform to a the crs needed to do the cartogram transformation
toy_merc <- st_transform(toy_temp_mean, 3857)
# cartogram transformation
toy_cartogram <- cartogram_cont(toy_merc, weight = "n", itermax = 5)
# Transform back to original crs 
toy_cartogram <- st_transform(toy_cartogram, st_crs(toy_temp_mean))

# Plot cartogram using ggplot2
ggplot(toy_cartogram) +
  geom_sf(aes(fill = temp_mean), linewidth = 0, alpha = 0.9) +
  theme_minimal() +
  scale_fill_distiller(palette = "YlOrRd", direction= 1) +
  xlab("Longitude") +
  ylab("Latitude") +
  labs(fill = "Temperature") +
  theme(aspect.ratio=0.7)
```

## Solution 

```{r}
#| label: example2-sol
#| echo: true

# only change to data is distribution
toy_cartogram |>
  mutate(temp_dist = distributional::dist_normal(temp_mean, temp_se^2)) |>
  ggplot() +
  geom_sf_sample(aes(geometry=county_geometry, 
                     fill=temp_dist), linewidth=0) +
   geom_sf(aes(geometry=county_geometry), fill=NA, colour="white") +
  theme_minimal() +
  scale_fill_distiller(palette = "YlOrRd", direction= 1) +
  xlab("Longitude") +
  ylab("Latitude") +
  labs(fill = "Temperature") +
  theme(aspect.ratio=0.7)
```
